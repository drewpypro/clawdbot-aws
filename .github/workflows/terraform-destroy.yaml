name: terraform destroy workflow

on:
  workflow_dispatch:

env:
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  BUCKET_NAME: ${{ secrets.BUCKET_NAME }}
  BUCKET_KEY: ${{ secrets.BUCKET_KEY }}
  BUCKET_ENDPOINT: ${{ secrets.BUCKET_ENDPOINT }}
  BUCKET_ACCESS_KEY_ID: ${{ secrets.BUCKET_ACCESS_KEY_ID }}
  BUCKET_SECRET_ACCESS_KEY: ${{ secrets.BUCKET_SECRET_ACCESS_KEY }}
  TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
  TF_VAR_allowed_ssh_cidrs: ${{ secrets.ALLOWED_SSH_CIDRS }}

jobs:
  terraform-destroy:
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/drewpypro/kube-aws-istio:latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Verify Backend
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BUCKET_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BUCKET_SECRET_ACCESS_KEY }}
        run: |
          echo "Runner IP: $(curl -s https://ifconfig.me/ip)"
          aws s3 ls s3://$BUCKET_NAME --endpoint-url $BUCKET_ENDPOINT

      - name: Terraform Init
        run: |
          terraform init \
            -backend-config="bucket=$BUCKET_NAME" \
            -backend-config="key=$BUCKET_KEY" \
            -backend-config="endpoint=$BUCKET_ENDPOINT" \
            -backend-config="access_key=$BUCKET_ACCESS_KEY_ID" \
            -backend-config="secret_key=$BUCKET_SECRET_ACCESS_KEY"

      - name: Terraform Destroy
        run: terraform destroy -auto-approve

      - name: Check for orphaned volumes
        if: always()
        run: |
          echo "üîç Checking for orphaned clawdbot EBS volumes..."
          REGION="${AWS_DEFAULT_REGION:-us-west-2}"
          ORPHANS=$(aws ec2 describe-volumes \
            --region "$REGION" \
            --filters "Name=tag:Project,Values=clawdbot" "Name=status,Values=available" \
            --query 'Volumes[*].[VolumeId,Size,CreateTime]' \
            --output text)
          
          if [ -z "$ORPHANS" ]; then
            echo "‚úÖ No orphaned clawdbot volumes found"
          else
            echo "‚ö†Ô∏è Found orphaned clawdbot volumes:"
            echo "$ORPHANS"
            echo ""
            echo "üóëÔ∏è Deleting orphaned volumes..."
            for vol_id in $(echo "$ORPHANS" | awk '{print $1}'); do
              echo "  Deleting $vol_id..."
              aws ec2 delete-volume --region "$REGION" --volume-id "$vol_id"
            done
            echo "‚úÖ Orphan cleanup complete"
          fi

      - name: Check for any untagged available volumes
        if: always()
        run: |
          echo "üîç Checking for untagged available volumes (potential orphans)..."
          REGION="${AWS_DEFAULT_REGION:-us-west-2}"
          ALL_AVAILABLE=$(aws ec2 describe-volumes \
            --region "$REGION" \
            --filters "Name=status,Values=available" \
            --query 'Volumes[*].[VolumeId,Size,CreateTime,Tags]' \
            --output json)
          echo "$ALL_AVAILABLE" | python3 -c "
          import sys, json
          vols = json.load(sys.stdin)
          if not vols:
              print('‚úÖ No available (unattached) volumes in the region')
          else:
              print(f'‚ö†Ô∏è Found {len(vols)} available volume(s) ‚Äî review manually:')
              for v in vols:
                  print(f'  {v[0]} | {v[1]}GB | Created: {v[2]}')
          "
